{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distilling the Knowledge in a Neural Network\n",
    "\n",
    "https://arxiv.org/pdf/1503.02531.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import models\n",
    "reload(models)\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist, cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1000\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(width_shift_range=0.1, \n",
    "                             height_shift_range=0.1,\n",
    "                             shear_range=0.1,\n",
    "                             zoom_range=0.1,\n",
    "                            )\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "#test_datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dict()\n",
    "hist = dict()\n",
    "score = dict()\n",
    "preds = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0930 20:05:20.835141 140488202495808 deprecation_wrapper.py:119] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0930 20:05:20.872389 140488202495808 deprecation_wrapper.py:119] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0930 20:05:20.880152 140488202495808 deprecation_wrapper.py:119] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0930 20:05:20.951750 140488202495808 deprecation_wrapper.py:119] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0930 20:05:20.957339 140488202495808 deprecation_wrapper.py:119] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0930 20:05:20.976952 140488202495808 deprecation.py:506] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0930 20:05:21.170324 140488202495808 deprecation_wrapper.py:119] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0930 20:05:21.220181 140488202495808 deprecation_wrapper.py:119] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                10250     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 20,084,106\n",
      "Trainable params: 20,084,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload(models)\n",
    "model['teacher'] = models.TeacherModel(input_shape, num_classes)\n",
    "\n",
    "model['teacher'].compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model['teacher'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0930 14:14:53.959012 140318191400768 deprecation.py:323] From /home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 27s 447ms/step - loss: 0.5800 - acc: 0.8056 - val_loss: 0.0629 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.06294, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 22s 366ms/step - loss: 0.1244 - acc: 0.9618 - val_loss: 0.0320 - val_acc: 0.9894\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.06294 to 0.03200, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 23s 388ms/step - loss: 0.0915 - acc: 0.9720 - val_loss: 0.0289 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03200 to 0.02891, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 23s 381ms/step - loss: 0.0729 - acc: 0.9783 - val_loss: 0.0277 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.02891 to 0.02767, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 23s 383ms/step - loss: 0.0677 - acc: 0.9782 - val_loss: 0.0258 - val_acc: 0.9908\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02767 to 0.02584, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 22s 367ms/step - loss: 0.0611 - acc: 0.9816 - val_loss: 0.0299 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02584\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 23s 376ms/step - loss: 0.0544 - acc: 0.9836 - val_loss: 0.0209 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02584 to 0.02087, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 23s 382ms/step - loss: 0.0498 - acc: 0.9847 - val_loss: 0.0207 - val_acc: 0.9931\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02087 to 0.02074, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 23s 387ms/step - loss: 0.0477 - acc: 0.9852 - val_loss: 0.0194 - val_acc: 0.9932\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02074 to 0.01939, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 24s 393ms/step - loss: 0.0455 - acc: 0.9862 - val_loss: 0.0197 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01939\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 24s 392ms/step - loss: 0.0424 - acc: 0.9872 - val_loss: 0.0187 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01939 to 0.01868, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 23s 391ms/step - loss: 0.0392 - acc: 0.9880 - val_loss: 0.0210 - val_acc: 0.9928\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01868\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 23s 389ms/step - loss: 0.0369 - acc: 0.9879 - val_loss: 0.0197 - val_acc: 0.9934\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01868\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 23s 381ms/step - loss: 0.0382 - acc: 0.9880 - val_loss: 0.0195 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01868\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 24s 392ms/step - loss: 0.0353 - acc: 0.9889 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01868\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 24s 395ms/step - loss: 0.0359 - acc: 0.9892 - val_loss: 0.0161 - val_acc: 0.9947\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01868 to 0.01613, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 24s 394ms/step - loss: 0.0347 - acc: 0.9897 - val_loss: 0.0177 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01613\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 23s 391ms/step - loss: 0.0319 - acc: 0.9903 - val_loss: 0.0172 - val_acc: 0.9949\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01613\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 24s 396ms/step - loss: 0.0295 - acc: 0.9908 - val_loss: 0.0188 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01613\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 24s 398ms/step - loss: 0.0295 - acc: 0.9910 - val_loss: 0.0179 - val_acc: 0.9940\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01613\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 24s 407ms/step - loss: 0.0286 - acc: 0.9913 - val_loss: 0.0160 - val_acc: 0.9945\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01613 to 0.01598, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 24s 404ms/step - loss: 0.0290 - acc: 0.9905 - val_loss: 0.0141 - val_acc: 0.9953\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01598 to 0.01409, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 24s 404ms/step - loss: 0.0260 - acc: 0.9918 - val_loss: 0.0186 - val_acc: 0.9939\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01409\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 24s 408ms/step - loss: 0.0278 - acc: 0.9918 - val_loss: 0.0162 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01409\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 26s 436ms/step - loss: 0.0261 - acc: 0.9918 - val_loss: 0.0194 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01409\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 25s 420ms/step - loss: 0.0254 - acc: 0.9923 - val_loss: 0.0143 - val_acc: 0.9956\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01409\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 23s 388ms/step - loss: 0.0250 - acc: 0.9923 - val_loss: 0.0153 - val_acc: 0.9951\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01409\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 26s 430ms/step - loss: 0.0250 - acc: 0.9926 - val_loss: 0.0174 - val_acc: 0.9944\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01409\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 26s 433ms/step - loss: 0.0230 - acc: 0.9934 - val_loss: 0.0157 - val_acc: 0.9952\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01409\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 25s 417ms/step - loss: 0.0247 - acc: 0.9925 - val_loss: 0.0172 - val_acc: 0.9942\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.01409\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 24s 406ms/step - loss: 0.0244 - acc: 0.9922 - val_loss: 0.0143 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01409\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 24s 408ms/step - loss: 0.0227 - acc: 0.9927 - val_loss: 0.0164 - val_acc: 0.9946\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01409\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 25s 420ms/step - loss: 0.0220 - acc: 0.9933 - val_loss: 0.0143 - val_acc: 0.9959\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01409\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 26s 440ms/step - loss: 0.0204 - acc: 0.9935 - val_loss: 0.0150 - val_acc: 0.9957\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01409\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 24s 400ms/step - loss: 0.0204 - acc: 0.9941 - val_loss: 0.0147 - val_acc: 0.9948\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01409\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 25s 419ms/step - loss: 0.0216 - acc: 0.9935 - val_loss: 0.0141 - val_acc: 0.9954\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.01409 to 0.01407, saving model to saved_models/weights.best.teacher.hdf5\n",
      "Epoch 37/100\n",
      "14/60 [======>.......................] - ETA: 19s - loss: 0.0207 - acc: 0.9929"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2af87d3cf1cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                                                            validation_steps=len(x_train) // batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m                                                            callbacks=[checkpointer])\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'teacher'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'teacher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'teacher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.teacher.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "hist['teacher'] = model['teacher'].fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                                           steps_per_epoch=len(x_train) // batch_size, \n",
    "                                                           epochs=100, verbose=1, \n",
    "#                                                            validation_data=test_datagen.flow(x_test, y_test), \n",
    "#                                                            validation_steps=len(x_train) // batch_size,\n",
    "                                                           validation_data=(x_test, y_test),\n",
    "                                                           callbacks=[checkpointer])\n",
    "score['teacher'] = model['teacher'].evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score['teacher'][0])\n",
    "print('Test accuracy:', score['teacher'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.014066617570716061\n",
      "Test accuracy: 0.9954\n",
      "Test errors: 46\n"
     ]
    }
   ],
   "source": [
    "model['teacher'].load_weights('saved_models/weights.best.teacher.hdf5')\n",
    "score['teacher'] = model['teacher'].evaluate(x_test, y_test, verbose=0)\n",
    "n_errors = np.int((1-score['teacher'][-1])*len(y_test))\n",
    "print('Test loss:', score['teacher'][0])\n",
    "print('Test accuracy:', score['teacher'][-1])\n",
    "print('Test errors:', n_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_29 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 26, 26, 128)       1280      \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 24, 24, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 18432)             0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 1024)              18875392  \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 20,084,106\n",
      "Trainable params: 20,084,106\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload(models)\n",
    "model['soft_teacher'] = models.SoftTeacherModel(input_shape, num_classes, l1=0.1, l2=0.07, b=4)\n",
    "\n",
    "model['soft_teacher'].compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model['soft_teacher'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "60/60 [==============================] - 25s 423ms/step - loss: 1.0397 - acc: 0.9913 - val_loss: 1.0202 - val_acc: 0.9945\n",
      "Epoch 2/30\n",
      "60/60 [==============================] - 20s 339ms/step - loss: 1.0357 - acc: 0.9920 - val_loss: 1.0179 - val_acc: 0.9951\n",
      "Epoch 3/30\n",
      "60/60 [==============================] - 24s 403ms/step - loss: 1.0335 - acc: 0.9922 - val_loss: 1.0176 - val_acc: 0.9942\n",
      "Epoch 4/30\n",
      "60/60 [==============================] - 30s 492ms/step - loss: 1.0321 - acc: 0.9919 - val_loss: 1.0160 - val_acc: 0.9936\n",
      "Epoch 5/30\n",
      "60/60 [==============================] - 31s 520ms/step - loss: 1.0315 - acc: 0.9919 - val_loss: 1.0165 - val_acc: 0.9939\n",
      "Epoch 6/30\n",
      "60/60 [==============================] - 32s 534ms/step - loss: 1.0296 - acc: 0.9928 - val_loss: 1.0147 - val_acc: 0.9939\n",
      "Epoch 7/30\n",
      "60/60 [==============================] - 38s 640ms/step - loss: 1.0292 - acc: 0.9931 - val_loss: 1.0172 - val_acc: 0.9936\n",
      "Epoch 8/30\n",
      "60/60 [==============================] - 38s 638ms/step - loss: 1.0283 - acc: 0.9931 - val_loss: 1.0141 - val_acc: 0.9951\n",
      "Epoch 9/30\n",
      "60/60 [==============================] - 38s 628ms/step - loss: 1.0281 - acc: 0.9928 - val_loss: 1.0132 - val_acc: 0.9950\n",
      "Epoch 10/30\n",
      "60/60 [==============================] - 39s 658ms/step - loss: 1.0275 - acc: 0.9928 - val_loss: 1.0141 - val_acc: 0.9940\n",
      "Epoch 11/30\n",
      "60/60 [==============================] - 38s 635ms/step - loss: 1.0263 - acc: 0.9930 - val_loss: 1.0135 - val_acc: 0.9943\n",
      "Epoch 12/30\n",
      "60/60 [==============================] - 37s 614ms/step - loss: 1.0256 - acc: 0.9936 - val_loss: 1.0130 - val_acc: 0.9941\n",
      "Epoch 13/30\n",
      "60/60 [==============================] - 41s 683ms/step - loss: 1.0255 - acc: 0.9931 - val_loss: 1.0133 - val_acc: 0.9945\n",
      "Epoch 14/30\n",
      "60/60 [==============================] - 37s 609ms/step - loss: 1.0244 - acc: 0.9938 - val_loss: 1.0125 - val_acc: 0.9938\n",
      "Epoch 15/30\n",
      "60/60 [==============================] - 38s 635ms/step - loss: 1.0251 - acc: 0.9932 - val_loss: 1.0119 - val_acc: 0.9952\n",
      "Epoch 16/30\n",
      "60/60 [==============================] - 37s 623ms/step - loss: 1.0243 - acc: 0.9934 - val_loss: 1.0120 - val_acc: 0.9938\n",
      "Epoch 17/30\n",
      "60/60 [==============================] - 39s 650ms/step - loss: 1.0239 - acc: 0.9941 - val_loss: 1.0125 - val_acc: 0.9938\n",
      "Epoch 18/30\n",
      " 8/60 [===>..........................] - ETA: 57s - loss: 1.0241 - acc: 0.9931 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-0c9aa14b6a73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#                                                            validation_steps=len(x_train) // batch_size,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                                            callbacks=[checkpointer])\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'soft_teacher'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'soft_teacher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'soft_teacher'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.soft_teacher.hdf5', \n",
    "                               verbose=0, save_best_only=True, monitor='val_acc')\n",
    "\n",
    "model['soft_teacher'].load_weights('saved_models/weights.best.soft_teacher.hdf5')\n",
    "hist['soft_teacher'] = model['soft_teacher'].fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                                           steps_per_epoch=len(x_train) // batch_size, \n",
    "                                                           epochs=30, verbose=1, \n",
    "#                                                            validation_data=test_datagen.flow(x_test, y_test), \n",
    "#                                                            validation_steps=len(x_train) // batch_size,\n",
    "                                                           validation_data=(x_test, y_test),\n",
    "                                                           callbacks=[checkpointer])\n",
    "score['soft_teacher'] = model['soft_teacher'].evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score['soft_teacher'][0])\n",
    "print('Test accuracy:', score['soft_teacher'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.8385954130172729\n",
      "Test accuracy: 0.9952\n",
      "Test errors: 48\n"
     ]
    }
   ],
   "source": [
    "model['soft_teacher'].load_weights('saved_models/weights.best.soft_teacher.hdf5')\n",
    "score['soft_teacher'] = model['soft_teacher'].evaluate(x_test, y_test, verbose=0)\n",
    "n_errors = np.int((1-score['soft_teacher'][-1])*len(y_test))\n",
    "print('Test loss:', score['soft_teacher'][0])\n",
    "print('Test accuracy:', score['soft_teacher'][-1])\n",
    "print('Test errors:', n_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 800)               628000    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 800)               640800    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                8010      \n",
      "_________________________________________________________________\n",
      "o2 (Activation)              (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,276,810\n",
      "Trainable params: 1,276,810\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "reload(models)\n",
    "model['student'] = models.StudentModel(input_shape, num_classes)\n",
    "\n",
    "model['student'].compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='Adam',\n",
    "              metrics=['accuracy'])\n",
    "model['student'].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 6s 99us/step - loss: 0.3994 - acc: 0.8890 - val_loss: 0.1743 - val_acc: 0.9483\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.1314 - acc: 0.9612 - val_loss: 0.1046 - val_acc: 0.9671\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0840 - acc: 0.9754 - val_loss: 0.0836 - val_acc: 0.9731\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0567 - acc: 0.9833 - val_loss: 0.0716 - val_acc: 0.9778\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0409 - acc: 0.9882 - val_loss: 0.0695 - val_acc: 0.9775\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0293 - acc: 0.9913 - val_loss: 0.0653 - val_acc: 0.9784\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0210 - acc: 0.9944 - val_loss: 0.0598 - val_acc: 0.9812\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0151 - acc: 0.9965 - val_loss: 0.0601 - val_acc: 0.9812\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0108 - acc: 0.9975 - val_loss: 0.0589 - val_acc: 0.9824\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.0071 - acc: 0.9985 - val_loss: 0.0607 - val_acc: 0.9818\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0044 - acc: 0.9995 - val_loss: 0.0585 - val_acc: 0.9829\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0031 - acc: 0.9998 - val_loss: 0.0625 - val_acc: 0.9819\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0019 - acc: 0.9999 - val_loss: 0.0602 - val_acc: 0.9829\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 0.9824\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 9.9836e-04 - acc: 1.0000 - val_loss: 0.0630 - val_acc: 0.9829\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 9.1339e-04 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9829\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 6.9194e-04 - acc: 1.0000 - val_loss: 0.0637 - val_acc: 0.9833\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 6.0353e-04 - acc: 1.0000 - val_loss: 0.0635 - val_acc: 0.9830\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 4.8143e-04 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 0.9833\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 4.2512e-04 - acc: 1.0000 - val_loss: 0.0648 - val_acc: 0.9834\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.7610e-04 - acc: 1.0000 - val_loss: 0.0658 - val_acc: 0.9835\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 3.3203e-04 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9834\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 3.0186e-04 - acc: 1.0000 - val_loss: 0.0664 - val_acc: 0.9835\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7000e-04 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9831\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.4848e-04 - acc: 1.0000 - val_loss: 0.0677 - val_acc: 0.9832\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.2603e-04 - acc: 1.0000 - val_loss: 0.0684 - val_acc: 0.9834\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.0857e-04 - acc: 1.0000 - val_loss: 0.0679 - val_acc: 0.9834\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.9140e-04 - acc: 1.0000 - val_loss: 0.0688 - val_acc: 0.9835\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.7410e-04 - acc: 1.0000 - val_loss: 0.0694 - val_acc: 0.9835\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.6170e-04 - acc: 1.0000 - val_loss: 0.0693 - val_acc: 0.9838\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4932e-04 - acc: 1.0000 - val_loss: 0.0698 - val_acc: 0.9834\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4044e-04 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9835\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.2919e-04 - acc: 1.0000 - val_loss: 0.0707 - val_acc: 0.9837\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1929e-04 - acc: 1.0000 - val_loss: 0.0711 - val_acc: 0.9836\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1085e-04 - acc: 1.0000 - val_loss: 0.0717 - val_acc: 0.9836\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.0372e-04 - acc: 1.0000 - val_loss: 0.0720 - val_acc: 0.9837\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 9.6566e-05 - acc: 1.0000 - val_loss: 0.0728 - val_acc: 0.9834\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 9.0870e-05 - acc: 1.0000 - val_loss: 0.0727 - val_acc: 0.9832\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 8.4937e-05 - acc: 1.0000 - val_loss: 0.0730 - val_acc: 0.9836\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 7.9950e-05 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9835\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 7.5187e-05 - acc: 1.0000 - val_loss: 0.0737 - val_acc: 0.9838\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 7.0492e-05 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9837\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 6.6079e-05 - acc: 1.0000 - val_loss: 0.0740 - val_acc: 0.9840\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 6.2058e-05 - acc: 1.0000 - val_loss: 0.0746 - val_acc: 0.9835\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 5.8910e-05 - acc: 1.0000 - val_loss: 0.0751 - val_acc: 0.9834\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 5.5272e-05 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 0.9834\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 5.1945e-05 - acc: 1.0000 - val_loss: 0.0757 - val_acc: 0.9839\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 4.9049e-05 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9833\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 4.6255e-05 - acc: 1.0000 - val_loss: 0.0764 - val_acc: 0.9836\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 4.3485e-05 - acc: 1.0000 - val_loss: 0.0767 - val_acc: 0.9838\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 4.1047e-05 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 0.9834\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 3.9162e-05 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 0.9836\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.6912e-05 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9835\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.5074e-05 - acc: 1.0000 - val_loss: 0.0779 - val_acc: 0.9836\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.3043e-05 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 0.9836\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 3.1235e-05 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9833\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.9678e-05 - acc: 1.0000 - val_loss: 0.0793 - val_acc: 0.9833\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.7851e-05 - acc: 1.0000 - val_loss: 0.0794 - val_acc: 0.9837\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.6647e-05 - acc: 1.0000 - val_loss: 0.0800 - val_acc: 0.9835\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 2.5237e-05 - acc: 1.0000 - val_loss: 0.0804 - val_acc: 0.9836\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 2.4007e-05 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9836\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.2627e-05 - acc: 1.0000 - val_loss: 0.0810 - val_acc: 0.9835\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1434e-05 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9836\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.0400e-05 - acc: 1.0000 - val_loss: 0.0814 - val_acc: 0.9837\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.9418e-05 - acc: 1.0000 - val_loss: 0.0818 - val_acc: 0.9837\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.8376e-05 - acc: 1.0000 - val_loss: 0.0820 - val_acc: 0.9836\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.7681e-05 - acc: 1.0000 - val_loss: 0.0827 - val_acc: 0.9835\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.6683e-05 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9836\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.5880e-05 - acc: 1.0000 - val_loss: 0.0829 - val_acc: 0.9835\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.5084e-05 - acc: 1.0000 - val_loss: 0.0836 - val_acc: 0.9834\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.4383e-05 - acc: 1.0000 - val_loss: 0.0835 - val_acc: 0.9837\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.3610e-05 - acc: 1.0000 - val_loss: 0.0839 - val_acc: 0.9838\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.3002e-05 - acc: 1.0000 - val_loss: 0.0842 - val_acc: 0.9836\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.2305e-05 - acc: 1.0000 - val_loss: 0.0848 - val_acc: 0.9836\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.1855e-05 - acc: 1.0000 - val_loss: 0.0850 - val_acc: 0.9834\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.1247e-05 - acc: 1.0000 - val_loss: 0.0853 - val_acc: 0.9836\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.0771e-05 - acc: 1.0000 - val_loss: 0.0855 - val_acc: 0.9837\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.0225e-05 - acc: 1.0000 - val_loss: 0.0857 - val_acc: 0.9838\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 9.7413e-06 - acc: 1.0000 - val_loss: 0.0863 - val_acc: 0.9834\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 9.2688e-06 - acc: 1.0000 - val_loss: 0.0865 - val_acc: 0.9834\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 8.8821e-06 - acc: 1.0000 - val_loss: 0.0869 - val_acc: 0.9834\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 8.5251e-06 - acc: 1.0000 - val_loss: 0.0872 - val_acc: 0.9836\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 8.0643e-06 - acc: 1.0000 - val_loss: 0.0873 - val_acc: 0.9838\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 7.7380e-06 - acc: 1.0000 - val_loss: 0.0878 - val_acc: 0.9835\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 7.4537e-06 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9834\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 7.0697e-06 - acc: 1.0000 - val_loss: 0.0882 - val_acc: 0.9837\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 6.7580e-06 - acc: 1.0000 - val_loss: 0.0886 - val_acc: 0.9836\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 6.4784e-06 - acc: 1.0000 - val_loss: 0.0890 - val_acc: 0.9836\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 6.1849e-06 - acc: 1.0000 - val_loss: 0.0893 - val_acc: 0.9834\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 5.9331e-06 - acc: 1.0000 - val_loss: 0.0895 - val_acc: 0.9837\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 5.6610e-06 - acc: 1.0000 - val_loss: 0.0897 - val_acc: 0.9836\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 5.4022e-06 - acc: 1.0000 - val_loss: 0.0903 - val_acc: 0.9834\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 5.2055e-06 - acc: 1.0000 - val_loss: 0.0907 - val_acc: 0.9836\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 4.9661e-06 - acc: 1.0000 - val_loss: 0.0909 - val_acc: 0.9834\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 4.7898e-06 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9834\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 4.5782e-06 - acc: 1.0000 - val_loss: 0.0912 - val_acc: 0.9836\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 4.3842e-06 - acc: 1.0000 - val_loss: 0.0914 - val_acc: 0.9836\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 4.2097e-06 - acc: 1.0000 - val_loss: 0.0918 - val_acc: 0.9835\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 4.0336e-06 - acc: 1.0000 - val_loss: 0.0922 - val_acc: 0.9836\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 3.8583e-06 - acc: 1.0000 - val_loss: 0.0925 - val_acc: 0.9834\n",
      "Test loss: 0.09252743596316784\n",
      "Test accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.student.hdf5', \n",
    "                               verbose=0, save_best_only=True, monitor='val_acc')\n",
    "\n",
    "hist['student'] = model['student'].fit(x_train, y_train, batch_size=batch_size,\n",
    "          epochs=100, verbose=1, validation_data=(x_test, y_test), callbacks=[checkpointer])\n",
    "score['student'] = model['student'].evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score['student'][0])\n",
    "print('Test accuracy:', score['student'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.074012807541752\n",
      "Test accuracy: 0.984\n",
      "Test errors: 160\n"
     ]
    }
   ],
   "source": [
    "model['student'].load_weights('saved_models/weights.best.student.hdf5')\n",
    "score['student'] = model['student'].evaluate(x_test, y_test, verbose=0)\n",
    "n_errors = np.int((1-score['student'][-1])*len(y_test))\n",
    "print('Test loss:', score['student'][0])\n",
    "print('Test accuracy:', score['student'][-1])\n",
    "print('Test errors:', n_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 65us/step\n",
      "10000/10000 [==============================] - 2s 162us/step\n",
      "60000/60000 [==============================] - 4s 72us/step\n",
      "10000/10000 [==============================] - 1s 55us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3622794, 0.53431916)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kd_gt = dict()\n",
    "T = 20\n",
    "kd_gt['t_train'] = model['teacher'].T_model(T).predict(x_train, verbose=1, batch_size=batch_size)\n",
    "kd_gt['t_test'] = model['teacher'].T_model(T).predict(x_test, verbose=1, batch_size=batch_size)\n",
    "kd_gt['st_train'] = model['soft_teacher'].predict(x_train, verbose=1, batch_size=batch_size)\n",
    "kd_gt['st_test'] = model['soft_teacher'].predict(x_test, verbose=1, batch_size=batch_size)\n",
    "\n",
    "import numpy as np\n",
    "np.linalg.norm(kd_gt['t_train'], axis=-1).mean(), np.linalg.norm(kd_gt['st_train'], axis=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from keras.activations import softmax\n",
    "\n",
    "# def softmax_with_temp(x):\n",
    "#     Temp = 1.0\n",
    "#     e_x = np.exp((x - x.max(axis=1, keepdims=True))/Temp)\n",
    "#     out = e_x / e_x.sum(axis=1, keepdims=True)\n",
    "#     return out\n",
    "\n",
    "# def soft_with_T(T=1):\n",
    "#     def swt(x):\n",
    "#         return softmax(x/T)\n",
    "#     return swt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' KNOWLEDGE DISTILLATION WITH REGULAR TEACHER (TEMPERATURE SOFTMAX) '''\n",
    "reload(models)\n",
    "model['student_'] = models.StudentModel(input_shape, num_classes, T=T, in_class=True)\n",
    "model['student_'].compile(loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "                          loss_weights=[1., 1. / (T**2)],\n",
    "                          optimizer='Adam',\n",
    "                          metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 4s 62us/step - loss: 2.2243 - o1_loss: 2.2225 - o2_loss: 0.6856 - o1_acc: 0.8270 - o2_acc: 0.8269 - val_loss: 2.1998 - val_o1_loss: 2.1989 - val_o2_loss: 0.3483 - val_o1_acc: 0.9288 - val_o2_acc: 0.9280\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1956 - o1_loss: 2.1949 - o2_loss: 0.2572 - o1_acc: 0.9435 - o2_acc: 0.9433 - val_loss: 2.1925 - val_o1_loss: 2.1920 - val_o2_loss: 0.1918 - val_o1_acc: 0.9580 - val_o2_acc: 0.9575\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1907 - o1_loss: 2.1903 - o2_loss: 0.1602 - o1_acc: 0.9640 - o2_acc: 0.9636 - val_loss: 2.1895 - val_o1_loss: 2.1892 - val_o2_loss: 0.1370 - val_o1_acc: 0.9693 - val_o2_acc: 0.9686\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1883 - o1_loss: 2.1880 - o2_loss: 0.1138 - o1_acc: 0.9735 - o2_acc: 0.9732 - val_loss: 2.1880 - val_o1_loss: 2.1877 - val_o2_loss: 0.1033 - val_o1_acc: 0.9758 - val_o2_acc: 0.9754\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1870 - o1_loss: 2.1867 - o2_loss: 0.0853 - o1_acc: 0.9791 - o2_acc: 0.9788 - val_loss: 2.1871 - val_o1_loss: 2.1869 - val_o2_loss: 0.0884 - val_o1_acc: 0.9779 - val_o2_acc: 0.9778\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1861 - o1_loss: 2.1860 - o2_loss: 0.0674 - o1_acc: 0.9828 - o2_acc: 0.9825 - val_loss: 2.1866 - val_o1_loss: 2.1864 - val_o2_loss: 0.0783 - val_o1_acc: 0.9803 - val_o2_acc: 0.9802\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1855 - o1_loss: 2.1854 - o2_loss: 0.0533 - o1_acc: 0.9859 - o2_acc: 0.9856 - val_loss: 2.1860 - val_o1_loss: 2.1859 - val_o2_loss: 0.0686 - val_o1_acc: 0.9835 - val_o2_acc: 0.9833\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1851 - o1_loss: 2.1850 - o2_loss: 0.0435 - o1_acc: 0.9887 - o2_acc: 0.9884 - val_loss: 2.1858 - val_o1_loss: 2.1857 - val_o2_loss: 0.0663 - val_o1_acc: 0.9839 - val_o2_acc: 0.9836\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 2.1848 - o1_loss: 2.1847 - o2_loss: 0.0354 - o1_acc: 0.9904 - o2_acc: 0.9902 - val_loss: 2.1856 - val_o1_loss: 2.1854 - val_o2_loss: 0.0600 - val_o1_acc: 0.9863 - val_o2_acc: 0.9862\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1845 - o1_loss: 2.1844 - o2_loss: 0.0297 - o1_acc: 0.9918 - o2_acc: 0.9915 - val_loss: 2.1853 - val_o1_loss: 2.1852 - val_o2_loss: 0.0574 - val_o1_acc: 0.9865 - val_o2_acc: 0.9864\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1843 - o1_loss: 2.1842 - o2_loss: 0.0253 - o1_acc: 0.9927 - o2_acc: 0.9926 - val_loss: 2.1852 - val_o1_loss: 2.1851 - val_o2_loss: 0.0545 - val_o1_acc: 0.9870 - val_o2_acc: 0.9867\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1841 - o1_loss: 2.1841 - o2_loss: 0.0219 - o1_acc: 0.9940 - o2_acc: 0.9938 - val_loss: 2.1852 - val_o1_loss: 2.1850 - val_o2_loss: 0.0518 - val_o1_acc: 0.9869 - val_o2_acc: 0.9865\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1839 - o1_loss: 2.1839 - o2_loss: 0.0182 - o1_acc: 0.9949 - o2_acc: 0.9947 - val_loss: 2.1850 - val_o1_loss: 2.1848 - val_o2_loss: 0.0491 - val_o1_acc: 0.9882 - val_o2_acc: 0.9876\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1838 - o1_loss: 2.1838 - o2_loss: 0.0160 - o1_acc: 0.9957 - o2_acc: 0.9955 - val_loss: 2.1849 - val_o1_loss: 2.1847 - val_o2_loss: 0.0485 - val_o1_acc: 0.9887 - val_o2_acc: 0.9881\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1837 - o1_loss: 2.1836 - o2_loss: 0.0138 - o1_acc: 0.9962 - o2_acc: 0.9960 - val_loss: 2.1848 - val_o1_loss: 2.1847 - val_o2_loss: 0.0465 - val_o1_acc: 0.9887 - val_o2_acc: 0.9881\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1836 - o1_loss: 2.1835 - o2_loss: 0.0123 - o1_acc: 0.9965 - o2_acc: 0.9962 - val_loss: 2.1848 - val_o1_loss: 2.1847 - val_o2_loss: 0.0483 - val_o1_acc: 0.9887 - val_o2_acc: 0.9884\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1835 - o1_loss: 2.1835 - o2_loss: 0.0111 - o1_acc: 0.9970 - o2_acc: 0.9968 - val_loss: 2.1847 - val_o1_loss: 2.1845 - val_o2_loss: 0.0470 - val_o1_acc: 0.9885 - val_o2_acc: 0.9884\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1834 - o1_loss: 2.1834 - o2_loss: 0.0099 - o1_acc: 0.9973 - o2_acc: 0.9972 - val_loss: 2.1846 - val_o1_loss: 2.1845 - val_o2_loss: 0.0448 - val_o1_acc: 0.9888 - val_o2_acc: 0.9886\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1833 - o1_loss: 2.1833 - o2_loss: 0.0091 - o1_acc: 0.9972 - o2_acc: 0.9972 - val_loss: 2.1846 - val_o1_loss: 2.1845 - val_o2_loss: 0.0451 - val_o1_acc: 0.9897 - val_o2_acc: 0.9889\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1833 - o1_loss: 2.1832 - o2_loss: 0.0081 - o1_acc: 0.9977 - o2_acc: 0.9978 - val_loss: 2.1845 - val_o1_loss: 2.1844 - val_o2_loss: 0.0439 - val_o1_acc: 0.9889 - val_o2_acc: 0.9883\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1832 - o1_loss: 2.1832 - o2_loss: 0.0074 - o1_acc: 0.9979 - o2_acc: 0.9979 - val_loss: 2.1846 - val_o1_loss: 2.1845 - val_o2_loss: 0.0441 - val_o1_acc: 0.9891 - val_o2_acc: 0.9884\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1832 - o1_loss: 2.1831 - o2_loss: 0.0068 - o1_acc: 0.9979 - o2_acc: 0.9980 - val_loss: 2.1845 - val_o1_loss: 2.1844 - val_o2_loss: 0.0417 - val_o1_acc: 0.9894 - val_o2_acc: 0.9893\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1831 - o1_loss: 2.1831 - o2_loss: 0.0063 - o1_acc: 0.9982 - o2_acc: 0.9982 - val_loss: 2.1844 - val_o1_loss: 2.1843 - val_o2_loss: 0.0419 - val_o1_acc: 0.9891 - val_o2_acc: 0.9888\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1830 - o1_loss: 2.1830 - o2_loss: 0.0059 - o1_acc: 0.9983 - o2_acc: 0.9984 - val_loss: 2.1844 - val_o1_loss: 2.1843 - val_o2_loss: 0.0406 - val_o1_acc: 0.9897 - val_o2_acc: 0.9892\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1830 - o1_loss: 2.1830 - o2_loss: 0.0054 - o1_acc: 0.9984 - o2_acc: 0.9985 - val_loss: 2.1844 - val_o1_loss: 2.1843 - val_o2_loss: 0.0405 - val_o1_acc: 0.9891 - val_o2_acc: 0.9885\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1830 - o1_loss: 2.1829 - o2_loss: 0.0052 - o1_acc: 0.9986 - o2_acc: 0.9988 - val_loss: 2.1844 - val_o1_loss: 2.1843 - val_o2_loss: 0.0404 - val_o1_acc: 0.9896 - val_o2_acc: 0.9894\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1829 - o1_loss: 2.1829 - o2_loss: 0.0050 - o1_acc: 0.9986 - o2_acc: 0.9987 - val_loss: 2.1844 - val_o1_loss: 2.1843 - val_o2_loss: 0.0407 - val_o1_acc: 0.9890 - val_o2_acc: 0.9883\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1829 - o1_loss: 2.1829 - o2_loss: 0.0047 - o1_acc: 0.9986 - o2_acc: 0.9989 - val_loss: 2.1844 - val_o1_loss: 2.1843 - val_o2_loss: 0.0395 - val_o1_acc: 0.9898 - val_o2_acc: 0.9896\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1829 - o1_loss: 2.1829 - o2_loss: 0.0044 - o1_acc: 0.9987 - o2_acc: 0.9990 - val_loss: 2.1843 - val_o1_loss: 2.1842 - val_o2_loss: 0.0403 - val_o1_acc: 0.9899 - val_o2_acc: 0.9896\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1828 - o1_loss: 2.1828 - o2_loss: 0.0041 - o1_acc: 0.9987 - o2_acc: 0.9991 - val_loss: 2.1843 - val_o1_loss: 2.1842 - val_o2_loss: 0.0402 - val_o1_acc: 0.9898 - val_o2_acc: 0.9894\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1828 - o1_loss: 2.1828 - o2_loss: 0.0040 - o1_acc: 0.9988 - o2_acc: 0.9991 - val_loss: 2.1843 - val_o1_loss: 2.1842 - val_o2_loss: 0.0371 - val_o1_acc: 0.9902 - val_o2_acc: 0.9904\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1828 - o1_loss: 2.1827 - o2_loss: 0.0039 - o1_acc: 0.9988 - o2_acc: 0.9991 - val_loss: 2.1843 - val_o1_loss: 2.1842 - val_o2_loss: 0.0391 - val_o1_acc: 0.9899 - val_o2_acc: 0.9894\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1827 - o1_loss: 2.1827 - o2_loss: 0.0037 - o1_acc: 0.9989 - o2_acc: 0.9991 - val_loss: 2.1843 - val_o1_loss: 2.1842 - val_o2_loss: 0.0389 - val_o1_acc: 0.9893 - val_o2_acc: 0.9891\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1827 - o1_loss: 2.1827 - o2_loss: 0.0036 - o1_acc: 0.9987 - o2_acc: 0.9992 - val_loss: 2.1843 - val_o1_loss: 2.1842 - val_o2_loss: 0.0385 - val_o1_acc: 0.9903 - val_o2_acc: 0.9897\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1827 - o1_loss: 2.1827 - o2_loss: 0.0034 - o1_acc: 0.9989 - o2_acc: 0.9991 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0379 - val_o1_acc: 0.9899 - val_o2_acc: 0.9893\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1827 - o1_loss: 2.1827 - o2_loss: 0.0033 - o1_acc: 0.9989 - o2_acc: 0.9993 - val_loss: 2.1843 - val_o1_loss: 2.1842 - val_o2_loss: 0.0377 - val_o1_acc: 0.9904 - val_o2_acc: 0.9902\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1827 - o1_loss: 2.1826 - o2_loss: 0.0032 - o1_acc: 0.9989 - o2_acc: 0.9993 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0380 - val_o1_acc: 0.9903 - val_o2_acc: 0.9900\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1826 - o1_loss: 2.1826 - o2_loss: 0.0030 - o1_acc: 0.9989 - o2_acc: 0.9993 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0359 - val_o1_acc: 0.9904 - val_o2_acc: 0.9902\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1826 - o1_loss: 2.1826 - o2_loss: 0.0030 - o1_acc: 0.9988 - o2_acc: 0.9993 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0378 - val_o1_acc: 0.9905 - val_o2_acc: 0.9901\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1826 - o1_loss: 2.1826 - o2_loss: 0.0029 - o1_acc: 0.9989 - o2_acc: 0.9993 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0375 - val_o1_acc: 0.9905 - val_o2_acc: 0.9898\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1826 - o1_loss: 2.1826 - o2_loss: 0.0028 - o1_acc: 0.9989 - o2_acc: 0.9994 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0364 - val_o1_acc: 0.9908 - val_o2_acc: 0.9906\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1826 - o1_loss: 2.1826 - o2_loss: 0.0028 - o1_acc: 0.9988 - o2_acc: 0.9994 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0361 - val_o1_acc: 0.9904 - val_o2_acc: 0.9898\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1826 - o1_loss: 2.1826 - o2_loss: 0.0027 - o1_acc: 0.9989 - o2_acc: 0.9994 - val_loss: 2.1841 - val_o1_loss: 2.1841 - val_o2_loss: 0.0360 - val_o1_acc: 0.9912 - val_o2_acc: 0.9906\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0026 - o1_acc: 0.9989 - o2_acc: 0.9995 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0363 - val_o1_acc: 0.9906 - val_o2_acc: 0.9900\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0025 - o1_acc: 0.9988 - o2_acc: 0.9995 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0363 - val_o1_acc: 0.9908 - val_o2_acc: 0.9898\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0025 - o1_acc: 0.9988 - o2_acc: 0.9995 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0364 - val_o1_acc: 0.9911 - val_o2_acc: 0.9905\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0025 - o1_acc: 0.9988 - o2_acc: 0.9995 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0362 - val_o1_acc: 0.9910 - val_o2_acc: 0.9902\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0024 - o1_acc: 0.9988 - o2_acc: 0.9995 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0358 - val_o1_acc: 0.9905 - val_o2_acc: 0.9903\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0023 - o1_acc: 0.9988 - o2_acc: 0.9995 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0353 - val_o1_acc: 0.9911 - val_o2_acc: 0.9904\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0024 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0367 - val_o1_acc: 0.9907 - val_o2_acc: 0.9904\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1825 - o1_loss: 2.1825 - o2_loss: 0.0024 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1841 - val_o2_loss: 0.0360 - val_o1_acc: 0.9912 - val_o2_acc: 0.9909\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0022 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0361 - val_o1_acc: 0.9910 - val_o2_acc: 0.9900\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0022 - o1_acc: 0.9987 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1841 - val_o2_loss: 0.0360 - val_o1_acc: 0.9914 - val_o2_acc: 0.9907\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0022 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0345 - val_o1_acc: 0.9912 - val_o2_acc: 0.9905\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0021 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1842 - val_o1_loss: 2.1841 - val_o2_loss: 0.0351 - val_o1_acc: 0.9911 - val_o2_acc: 0.9907\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0022 - o1_acc: 0.9988 - o2_acc: 0.9995 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0355 - val_o1_acc: 0.9908 - val_o2_acc: 0.9901\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0021 - o1_acc: 0.9987 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0357 - val_o1_acc: 0.9911 - val_o2_acc: 0.9900\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0021 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1841 - val_o2_loss: 0.0346 - val_o1_acc: 0.9912 - val_o2_acc: 0.9904\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0021 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0358 - val_o1_acc: 0.9909 - val_o2_acc: 0.9900\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0022 - o1_acc: 0.9987 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0352 - val_o1_acc: 0.9911 - val_o2_acc: 0.9906\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0020 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1841 - val_o2_loss: 0.0354 - val_o1_acc: 0.9911 - val_o2_acc: 0.9903\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1824 - o1_loss: 2.1824 - o2_loss: 0.0020 - o1_acc: 0.9988 - o2_acc: 0.9995 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0355 - val_o1_acc: 0.9913 - val_o2_acc: 0.9902\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1824 - o1_loss: 2.1823 - o2_loss: 0.0020 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0347 - val_o1_acc: 0.9918 - val_o2_acc: 0.9909\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0020 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0348 - val_o1_acc: 0.9915 - val_o2_acc: 0.9907\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0019 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0354 - val_o1_acc: 0.9911 - val_o2_acc: 0.9905\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0019 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0350 - val_o1_acc: 0.9916 - val_o2_acc: 0.9907\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0020 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1841 - val_o2_loss: 0.0344 - val_o1_acc: 0.9918 - val_o2_acc: 0.9909\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0019 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0350 - val_o1_acc: 0.9915 - val_o2_acc: 0.9904\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0020 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0346 - val_o1_acc: 0.9911 - val_o2_acc: 0.9903\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0019 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0351 - val_o1_acc: 0.9916 - val_o2_acc: 0.9904\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0019 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0337 - val_o1_acc: 0.9916 - val_o2_acc: 0.9910\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0358 - val_o1_acc: 0.9914 - val_o2_acc: 0.9904\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0344 - val_o1_acc: 0.9915 - val_o2_acc: 0.9911\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0345 - val_o1_acc: 0.9913 - val_o2_acc: 0.9905\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0344 - val_o1_acc: 0.9914 - val_o2_acc: 0.9908\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0343 - val_o1_acc: 0.9913 - val_o2_acc: 0.9903\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0346 - val_o1_acc: 0.9912 - val_o2_acc: 0.9906\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9988 - o2_acc: 0.9996 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0347 - val_o1_acc: 0.9913 - val_o2_acc: 0.9903\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0348 - val_o1_acc: 0.9917 - val_o2_acc: 0.9909\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0349 - val_o1_acc: 0.9910 - val_o2_acc: 0.9902\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0334 - val_o1_acc: 0.9915 - val_o2_acc: 0.9906\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1823 - o1_loss: 2.1823 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0345 - val_o1_acc: 0.9912 - val_o2_acc: 0.9903\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0343 - val_o1_acc: 0.9917 - val_o2_acc: 0.9907\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0018 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0343 - val_o1_acc: 0.9912 - val_o2_acc: 0.9906\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0341 - val_o1_acc: 0.9914 - val_o2_acc: 0.9906\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0346 - val_o1_acc: 0.9911 - val_o2_acc: 0.9905\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1823 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9986 - o2_acc: 0.9998 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0336 - val_o1_acc: 0.9913 - val_o2_acc: 0.9907\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0337 - val_o1_acc: 0.9913 - val_o2_acc: 0.9903\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9986 - o2_acc: 0.9998 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0341 - val_o1_acc: 0.9915 - val_o2_acc: 0.9907\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0346 - val_o1_acc: 0.9915 - val_o2_acc: 0.9905\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0339 - val_o1_acc: 0.9916 - val_o2_acc: 0.9910\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0016 - o1_acc: 0.9986 - o2_acc: 0.9998 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0333 - val_o1_acc: 0.9914 - val_o2_acc: 0.9906\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0331 - val_o1_acc: 0.9917 - val_o2_acc: 0.9911\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0016 - o1_acc: 0.9986 - o2_acc: 0.9998 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0335 - val_o1_acc: 0.9915 - val_o2_acc: 0.9907\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0343 - val_o1_acc: 0.9916 - val_o2_acc: 0.9906\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9986 - o2_acc: 0.9998 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0339 - val_o1_acc: 0.9913 - val_o2_acc: 0.9903\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0016 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0342 - val_o1_acc: 0.9918 - val_o2_acc: 0.9910\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0016 - o1_acc: 0.9987 - o2_acc: 0.9997 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0335 - val_o1_acc: 0.9920 - val_o2_acc: 0.9913\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0017 - o1_acc: 0.9986 - o2_acc: 0.9998 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0340 - val_o1_acc: 0.9917 - val_o2_acc: 0.9911\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 2.1822 - o1_loss: 2.1822 - o2_loss: 0.0016 - o1_acc: 0.9986 - o2_acc: 0.9998 - val_loss: 2.1841 - val_o1_loss: 2.1840 - val_o2_loss: 0.0339 - val_o1_acc: 0.9919 - val_o2_acc: 0.9909\n",
      "Test loss: 2.1841186248779296\n",
      "Test accuracy: 0.9909\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.student_.hdf5', \n",
    "                               verbose=0, save_best_only=True, monitor='val_loss')\n",
    "\n",
    "hist['student_'] = model['student_'].fit(x_train, [kd_gt['t_train'], y_train],\n",
    "          batch_size=batch_size, epochs=100, verbose=1,\n",
    "          validation_data=(x_test, [kd_gt['t_test'], y_test]), callbacks=[checkpointer])\n",
    "score['student_'] = model['student_'].evaluate(x_test, [kd_gt['t_test'], y_test], verbose=0)\n",
    "print('Test loss:', score['student_'][0])\n",
    "print('Test accuracy:', score['student_'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.184079764175415\n",
      "Test accuracy: 0.991\n",
      "Test errors: 90\n"
     ]
    }
   ],
   "source": [
    "model['student_'].load_weights('saved_models/weights.best.student_.hdf5')\n",
    "score['student_'] = model['student_'].evaluate(x_test, [kd_gt['t_test'], y_test], verbose=0)\n",
    "n_errors = np.int((1-score['student_'][-1])*len(y_test))\n",
    "print('Test loss:', score['student_'][0])\n",
    "print('Test accuracy:', score['student_'][-1])\n",
    "print('Test errors:', n_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' SOFT TEACHER IN CLASS '''\n",
    "reload(models)\n",
    "from keras import callbacks\n",
    "\n",
    "base_lr = 3e-3\n",
    "decay = 0.99\n",
    "optim = keras.optimizers.Adam(lr=base_lr)\n",
    "\n",
    "model['student_st'] = models.StudentModel(input_shape, num_classes, T=1, in_class=True, l2=0, b=0)\n",
    "model['student_st'].compile(loss=['categorical_crossentropy', 'categorical_crossentropy'],\n",
    "                          loss_weights=[0.05, 1],\n",
    "                          optimizer='Adam',\n",
    "                          metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/400\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.5644 - o1_loss: 3.3703 - o2_loss: 0.3959 - o1_acc: 0.8943 - o2_acc: 0.8942 - val_loss: 0.3446 - val_o1_loss: 3.2708 - val_o2_loss: 0.1810 - val_o1_acc: 0.9532 - val_o2_acc: 0.9530\n",
      "Epoch 2/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.3058 - o1_loss: 3.1802 - o2_loss: 0.1468 - o1_acc: 0.9659 - o2_acc: 0.9659 - val_loss: 0.2828 - val_o1_loss: 3.1394 - val_o2_loss: 0.1259 - val_o1_acc: 0.9723 - val_o2_acc: 0.9726\n",
      "Epoch 3/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2601 - o1_loss: 3.1465 - o2_loss: 0.1027 - o1_acc: 0.9799 - o2_acc: 0.9800 - val_loss: 0.2616 - val_o1_loss: 3.1469 - val_o2_loss: 0.1042 - val_o1_acc: 0.9774 - val_o2_acc: 0.9776\n",
      "Epoch 4/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2367 - o1_loss: 3.1234 - o2_loss: 0.0805 - o1_acc: 0.9872 - o2_acc: 0.9874 - val_loss: 0.2502 - val_o1_loss: 3.1115 - val_o2_loss: 0.0946 - val_o1_acc: 0.9799 - val_o2_acc: 0.9806\n",
      "Epoch 5/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2217 - o1_loss: 3.0964 - o2_loss: 0.0668 - o1_acc: 0.9915 - o2_acc: 0.9918 - val_loss: 0.2421 - val_o1_loss: 3.1122 - val_o2_loss: 0.0865 - val_o1_acc: 0.9826 - val_o2_acc: 0.9828\n",
      "Epoch 6/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.2103 - o1_loss: 3.0731 - o2_loss: 0.0567 - o1_acc: 0.9941 - o2_acc: 0.9950 - val_loss: 0.2338 - val_o1_loss: 3.0607 - val_o2_loss: 0.0808 - val_o1_acc: 0.9846 - val_o2_acc: 0.9854\n",
      "Epoch 7/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2024 - o1_loss: 3.0505 - o2_loss: 0.0498 - o1_acc: 0.9958 - o2_acc: 0.9970 - val_loss: 0.2317 - val_o1_loss: 3.0465 - val_o2_loss: 0.0794 - val_o1_acc: 0.9839 - val_o2_acc: 0.9841\n",
      "Epoch 8/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1964 - o1_loss: 3.0332 - o2_loss: 0.0448 - o1_acc: 0.9969 - o2_acc: 0.9983 - val_loss: 0.2284 - val_o1_loss: 3.0616 - val_o2_loss: 0.0754 - val_o1_acc: 0.9853 - val_o2_acc: 0.9856\n",
      "Epoch 9/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1923 - o1_loss: 3.0196 - o2_loss: 0.0413 - o1_acc: 0.9974 - o2_acc: 0.9990 - val_loss: 0.2258 - val_o1_loss: 3.0112 - val_o2_loss: 0.0752 - val_o1_acc: 0.9858 - val_o2_acc: 0.9859\n",
      "Epoch 10/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1889 - o1_loss: 3.0047 - o2_loss: 0.0386 - o1_acc: 0.9975 - o2_acc: 0.9995 - val_loss: 0.2239 - val_o1_loss: 2.9890 - val_o2_loss: 0.0745 - val_o1_acc: 0.9862 - val_o2_acc: 0.9862\n",
      "Epoch 11/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1860 - o1_loss: 2.9854 - o2_loss: 0.0367 - o1_acc: 0.9976 - o2_acc: 0.9997 - val_loss: 0.2215 - val_o1_loss: 2.9356 - val_o2_loss: 0.0747 - val_o1_acc: 0.9866 - val_o2_acc: 0.9868\n",
      "Epoch 12/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1838 - o1_loss: 2.9742 - o2_loss: 0.0351 - o1_acc: 0.9975 - o2_acc: 0.9999 - val_loss: 0.2215 - val_o1_loss: 2.9392 - val_o2_loss: 0.0746 - val_o1_acc: 0.9857 - val_o2_acc: 0.9861\n",
      "Epoch 13/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1820 - o1_loss: 2.9627 - o2_loss: 0.0339 - o1_acc: 0.9976 - o2_acc: 0.9999 - val_loss: 0.2191 - val_o1_loss: 2.9224 - val_o2_loss: 0.0730 - val_o1_acc: 0.9868 - val_o2_acc: 0.9871\n",
      "Epoch 14/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1802 - o1_loss: 2.9482 - o2_loss: 0.0328 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2181 - val_o1_loss: 2.9226 - val_o2_loss: 0.0719 - val_o1_acc: 0.9869 - val_o2_acc: 0.9874\n",
      "Epoch 15/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1791 - o1_loss: 2.9393 - o2_loss: 0.0321 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2180 - val_o1_loss: 2.9239 - val_o2_loss: 0.0718 - val_o1_acc: 0.9861 - val_o2_acc: 0.9869\n",
      "Epoch 16/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1781 - o1_loss: 2.9320 - o2_loss: 0.0315 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2168 - val_o1_loss: 2.9178 - val_o2_loss: 0.0709 - val_o1_acc: 0.9866 - val_o2_acc: 0.9872\n",
      "Epoch 17/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1771 - o1_loss: 2.9222 - o2_loss: 0.0310 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2165 - val_o1_loss: 2.8943 - val_o2_loss: 0.0718 - val_o1_acc: 0.9865 - val_o2_acc: 0.9866\n",
      "Epoch 18/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1763 - o1_loss: 2.9165 - o2_loss: 0.0305 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2151 - val_o1_loss: 2.9040 - val_o2_loss: 0.0699 - val_o1_acc: 0.9866 - val_o2_acc: 0.9870\n",
      "Epoch 19/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1756 - o1_loss: 2.9103 - o2_loss: 0.0301 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2149 - val_o1_loss: 2.8828 - val_o2_loss: 0.0708 - val_o1_acc: 0.9861 - val_o2_acc: 0.9865\n",
      "Epoch 20/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1750 - o1_loss: 2.9049 - o2_loss: 0.0298 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2144 - val_o1_loss: 2.8562 - val_o2_loss: 0.0716 - val_o1_acc: 0.9869 - val_o2_acc: 0.9871\n",
      "Epoch 21/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1744 - o1_loss: 2.8989 - o2_loss: 0.0294 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2140 - val_o1_loss: 2.8571 - val_o2_loss: 0.0712 - val_o1_acc: 0.9870 - val_o2_acc: 0.9874\n",
      "Epoch 22/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1740 - o1_loss: 2.8947 - o2_loss: 0.0292 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2145 - val_o1_loss: 2.8631 - val_o2_loss: 0.0713 - val_o1_acc: 0.9869 - val_o2_acc: 0.9873\n",
      "Epoch 23/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1735 - o1_loss: 2.8907 - o2_loss: 0.0290 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2126 - val_o1_loss: 2.8630 - val_o2_loss: 0.0694 - val_o1_acc: 0.9883 - val_o2_acc: 0.9884\n",
      "Epoch 24/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1731 - o1_loss: 2.8869 - o2_loss: 0.0288 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2128 - val_o1_loss: 2.8563 - val_o2_loss: 0.0700 - val_o1_acc: 0.9880 - val_o2_acc: 0.9882\n",
      "Epoch 25/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1728 - o1_loss: 2.8842 - o2_loss: 0.0286 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2126 - val_o1_loss: 2.8404 - val_o2_loss: 0.0706 - val_o1_acc: 0.9876 - val_o2_acc: 0.9880\n",
      "Epoch 26/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1725 - o1_loss: 2.8802 - o2_loss: 0.0284 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2119 - val_o1_loss: 2.8258 - val_o2_loss: 0.0706 - val_o1_acc: 0.9875 - val_o2_acc: 0.9877\n",
      "Epoch 27/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1721 - o1_loss: 2.8765 - o2_loss: 0.0283 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2125 - val_o1_loss: 2.8305 - val_o2_loss: 0.0710 - val_o1_acc: 0.9875 - val_o2_acc: 0.9878\n",
      "Epoch 28/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1719 - o1_loss: 2.8751 - o2_loss: 0.0281 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2121 - val_o1_loss: 2.8090 - val_o2_loss: 0.0716 - val_o1_acc: 0.9871 - val_o2_acc: 0.9877\n",
      "Epoch 29/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1716 - o1_loss: 2.8712 - o2_loss: 0.0280 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2115 - val_o1_loss: 2.8171 - val_o2_loss: 0.0707 - val_o1_acc: 0.9872 - val_o2_acc: 0.9881\n",
      "Epoch 30/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1714 - o1_loss: 2.8686 - o2_loss: 0.0279 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2117 - val_o1_loss: 2.8166 - val_o2_loss: 0.0709 - val_o1_acc: 0.9870 - val_o2_acc: 0.9875\n",
      "Epoch 31/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1712 - o1_loss: 2.8680 - o2_loss: 0.0278 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2113 - val_o1_loss: 2.8121 - val_o2_loss: 0.0707 - val_o1_acc: 0.9871 - val_o2_acc: 0.9876\n",
      "Epoch 32/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1710 - o1_loss: 2.8649 - o2_loss: 0.0277 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2112 - val_o1_loss: 2.8280 - val_o2_loss: 0.0698 - val_o1_acc: 0.9869 - val_o2_acc: 0.9874\n",
      "Epoch 33/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1709 - o1_loss: 2.8647 - o2_loss: 0.0276 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2111 - val_o1_loss: 2.8042 - val_o2_loss: 0.0709 - val_o1_acc: 0.9872 - val_o2_acc: 0.9878\n",
      "Epoch 34/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1707 - o1_loss: 2.8621 - o2_loss: 0.0276 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2108 - val_o1_loss: 2.8116 - val_o2_loss: 0.0702 - val_o1_acc: 0.9870 - val_o2_acc: 0.9878\n",
      "Epoch 35/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1705 - o1_loss: 2.8610 - o2_loss: 0.0275 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2107 - val_o1_loss: 2.7947 - val_o2_loss: 0.0709 - val_o1_acc: 0.9875 - val_o2_acc: 0.9883\n",
      "Epoch 36/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1704 - o1_loss: 2.8592 - o2_loss: 0.0274 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2104 - val_o1_loss: 2.8120 - val_o2_loss: 0.0698 - val_o1_acc: 0.9870 - val_o2_acc: 0.9876\n",
      "Epoch 37/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1703 - o1_loss: 2.8584 - o2_loss: 0.0274 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2102 - val_o1_loss: 2.7924 - val_o2_loss: 0.0705 - val_o1_acc: 0.9874 - val_o2_acc: 0.9880\n",
      "Epoch 38/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1702 - o1_loss: 2.8569 - o2_loss: 0.0273 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2099 - val_o1_loss: 2.7835 - val_o2_loss: 0.0707 - val_o1_acc: 0.9874 - val_o2_acc: 0.9880\n",
      "Epoch 39/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1701 - o1_loss: 2.8553 - o2_loss: 0.0273 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2100 - val_o1_loss: 2.8216 - val_o2_loss: 0.0689 - val_o1_acc: 0.9871 - val_o2_acc: 0.9878\n",
      "Epoch 40/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1700 - o1_loss: 2.8552 - o2_loss: 0.0272 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2097 - val_o1_loss: 2.8077 - val_o2_loss: 0.0693 - val_o1_acc: 0.9874 - val_o2_acc: 0.9878\n",
      "Epoch 41/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1699 - o1_loss: 2.8536 - o2_loss: 0.0272 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2097 - val_o1_loss: 2.8019 - val_o2_loss: 0.0696 - val_o1_acc: 0.9877 - val_o2_acc: 0.9883\n",
      "Epoch 42/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1698 - o1_loss: 2.8532 - o2_loss: 0.0272 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2097 - val_o1_loss: 2.8091 - val_o2_loss: 0.0693 - val_o1_acc: 0.9876 - val_o2_acc: 0.9883\n",
      "Epoch 43/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1697 - o1_loss: 2.8521 - o2_loss: 0.0271 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2095 - val_o1_loss: 2.8054 - val_o2_loss: 0.0693 - val_o1_acc: 0.9878 - val_o2_acc: 0.9884\n",
      "Epoch 44/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1697 - o1_loss: 2.8520 - o2_loss: 0.0271 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2094 - val_o1_loss: 2.8061 - val_o2_loss: 0.0691 - val_o1_acc: 0.9876 - val_o2_acc: 0.9880\n",
      "Epoch 45/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1696 - o1_loss: 2.8509 - o2_loss: 0.0270 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2090 - val_o1_loss: 2.8030 - val_o2_loss: 0.0689 - val_o1_acc: 0.9875 - val_o2_acc: 0.9881\n",
      "Epoch 46/400\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.1695 - o1_loss: 2.8500 - o2_loss: 0.0270 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2092 - val_o1_loss: 2.8066 - val_o2_loss: 0.0688 - val_o1_acc: 0.9874 - val_o2_acc: 0.9881\n",
      "Epoch 47/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1695 - o1_loss: 2.8495 - o2_loss: 0.0270 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2092 - val_o1_loss: 2.7921 - val_o2_loss: 0.0695 - val_o1_acc: 0.9874 - val_o2_acc: 0.9879\n",
      "Epoch 48/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1694 - o1_loss: 2.8487 - o2_loss: 0.0270 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2090 - val_o1_loss: 2.7916 - val_o2_loss: 0.0694 - val_o1_acc: 0.9872 - val_o2_acc: 0.9878\n",
      "Epoch 49/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1694 - o1_loss: 2.8483 - o2_loss: 0.0269 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2091 - val_o1_loss: 2.7954 - val_o2_loss: 0.0693 - val_o1_acc: 0.9873 - val_o2_acc: 0.9878\n",
      "Epoch 50/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1693 - o1_loss: 2.8476 - o2_loss: 0.0269 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2092 - val_o1_loss: 2.7867 - val_o2_loss: 0.0699 - val_o1_acc: 0.9874 - val_o2_acc: 0.9881\n",
      "Epoch 51/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1693 - o1_loss: 2.8469 - o2_loss: 0.0269 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2088 - val_o1_loss: 2.7933 - val_o2_loss: 0.0691 - val_o1_acc: 0.9874 - val_o2_acc: 0.9879\n",
      "Epoch 52/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1692 - o1_loss: 2.8470 - o2_loss: 0.0269 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2088 - val_o1_loss: 2.8031 - val_o2_loss: 0.0687 - val_o1_acc: 0.9874 - val_o2_acc: 0.9879\n",
      "Epoch 53/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1692 - o1_loss: 2.8463 - o2_loss: 0.0269 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2089 - val_o1_loss: 2.7925 - val_o2_loss: 0.0692 - val_o1_acc: 0.9872 - val_o2_acc: 0.9878\n",
      "Epoch 54/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1692 - o1_loss: 2.8461 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2087 - val_o1_loss: 2.7884 - val_o2_loss: 0.0692 - val_o1_acc: 0.9875 - val_o2_acc: 0.9881\n",
      "Epoch 55/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1691 - o1_loss: 2.8460 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2092 - val_o1_loss: 2.7621 - val_o2_loss: 0.0711 - val_o1_acc: 0.9873 - val_o2_acc: 0.9878\n",
      "Epoch 56/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1691 - o1_loss: 2.8450 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2086 - val_o1_loss: 2.7856 - val_o2_loss: 0.0693 - val_o1_acc: 0.9873 - val_o2_acc: 0.9879\n",
      "Epoch 57/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1691 - o1_loss: 2.8450 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2086 - val_o1_loss: 2.7654 - val_o2_loss: 0.0703 - val_o1_acc: 0.9872 - val_o2_acc: 0.9878\n",
      "Epoch 58/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1690 - o1_loss: 2.8441 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2084 - val_o1_loss: 2.8117 - val_o2_loss: 0.0678 - val_o1_acc: 0.9876 - val_o2_acc: 0.9880\n",
      "Epoch 59/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1690 - o1_loss: 2.8450 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2086 - val_o1_loss: 2.7856 - val_o2_loss: 0.0693 - val_o1_acc: 0.9875 - val_o2_acc: 0.9881\n",
      "Epoch 60/400\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 0.1690 - o1_loss: 2.8445 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2086 - val_o1_loss: 2.7726 - val_o2_loss: 0.0699 - val_o1_acc: 0.9875 - val_o2_acc: 0.9882\n",
      "Epoch 61/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1690 - o1_loss: 2.8437 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2089 - val_o1_loss: 2.7711 - val_o2_loss: 0.0704 - val_o1_acc: 0.9868 - val_o2_acc: 0.9873\n",
      "Epoch 62/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1689 - o1_loss: 2.8436 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2087 - val_o1_loss: 2.7581 - val_o2_loss: 0.0708 - val_o1_acc: 0.9870 - val_o2_acc: 0.9876\n",
      "Epoch 63/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1689 - o1_loss: 2.8431 - o2_loss: 0.0268 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2086 - val_o1_loss: 2.7781 - val_o2_loss: 0.0697 - val_o1_acc: 0.9869 - val_o2_acc: 0.9875\n",
      "Epoch 64/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1689 - o1_loss: 2.8430 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2085 - val_o1_loss: 2.7685 - val_o2_loss: 0.0701 - val_o1_acc: 0.9869 - val_o2_acc: 0.9875\n",
      "Epoch 65/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1689 - o1_loss: 2.8428 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2084 - val_o1_loss: 2.7758 - val_o2_loss: 0.0696 - val_o1_acc: 0.9872 - val_o2_acc: 0.9878\n",
      "Epoch 66/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1688 - o1_loss: 2.8421 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2084 - val_o1_loss: 2.8133 - val_o2_loss: 0.0677 - val_o1_acc: 0.9872 - val_o2_acc: 0.9877\n",
      "Epoch 67/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1688 - o1_loss: 2.8423 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2083 - val_o1_loss: 2.7917 - val_o2_loss: 0.0687 - val_o1_acc: 0.9871 - val_o2_acc: 0.9877\n",
      "Epoch 68/400\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 0.1688 - o1_loss: 2.8424 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2085 - val_o1_loss: 2.7858 - val_o2_loss: 0.0692 - val_o1_acc: 0.9867 - val_o2_acc: 0.9873\n",
      "Epoch 69/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1688 - o1_loss: 2.8420 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2082 - val_o1_loss: 2.7516 - val_o2_loss: 0.0707 - val_o1_acc: 0.9873 - val_o2_acc: 0.9879\n",
      "Epoch 70/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1688 - o1_loss: 2.8418 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2085 - val_o1_loss: 2.7736 - val_o2_loss: 0.0698 - val_o1_acc: 0.9873 - val_o2_acc: 0.9877\n",
      "Epoch 71/400\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.1688 - o1_loss: 2.8414 - o2_loss: 0.0267 - o1_acc: 0.9976 - o2_acc: 1.0000 - val_loss: 0.2088 - val_o1_loss: 2.7912 - val_o2_loss: 0.0692 - val_o1_acc: 0.9873 - val_o2_acc: 0.9879\n",
      "Epoch 72/400\n",
      "22000/60000 [==========>...................] - ETA: 0s - loss: 0.1688 - o1_loss: 2.8427 - o2_loss: 0.0267 - o1_acc: 0.9978 - o2_acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-999d00ebd7f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkd_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'st_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             )\n\u001b[1;32m     19\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'student_st'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'student_st'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkd_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'st_test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def schedule(epoch):\n",
    "    return base_lr * decay**(epoch)\n",
    "\n",
    "#es = callbacks.EarlyStopping(monitor='val_o2_loss', mode='min', verbose=0, patience=30)\n",
    "#mc = callbacks.ModelCheckpoint('best_student_st.h5', monitor='val_o2_acc', mode='max', verbose=0, save_best_only=True)\n",
    "ls = callbacks.LearningRateScheduler(schedule)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.student_st.hdf5', \n",
    "                               verbose=0, save_best_only=True, monitor='val_o2_acc')\n",
    "\n",
    "# model['student_st'].load_weights('saved_models/weights.best.student_st.hdf5')\n",
    "hist['student_st'] = model['student_st'].fit(x_train, [kd_gt['st_train'], y_train],\n",
    "          batch_size=batch_size,\n",
    "          epochs=400,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, [kd_gt['st_test'], y_test]),\n",
    "          callbacks=[checkpointer],\n",
    "            )\n",
    "score['student_st'] = model['student_st'].evaluate(x_test, [kd_gt['st_test'], y_test], verbose=0)\n",
    "print('Test loss:', score['student_st'][0])\n",
    "print('Test accuracy:', score['student_st'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model['student_st'].load_weights('saved_models/weights.best.student_st.hdf5')\n",
    "score['student_st'] = model['student_st'].evaluate(x_test, [kd_gt['st_test'], y_test], verbose=0)\n",
    "n_errors = np.int((1-score['student_st'][-1])*len(y_test))\n",
    "print('Test loss:', score['student_st'][0])\n",
    "print('Test accuracy:', score['student_st'][-1])\n",
    "print('Test errors:', n_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53869, 28, 28, 1)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_small_train = x_train[np.argmax(y_train, axis=-1) != 3]\n",
    "# y_small_train = y_train[np.argmax(y_train, axis=-1) != 3]\n",
    "# x_small_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(models)\n",
    "from keras import callbacks\n",
    "\n",
    "base_l2 = 0.05\n",
    "l2_decay = 0.98\n",
    "l2_weight = K.variable(base_l2)\n",
    "\n",
    "def changeAlpha(epoch,logs):\n",
    "    #maybe use epoch+1, because it starts with 0\n",
    "    K.set_value(l2_weight, base_l2 * l2_decay**epoch)\n",
    "\n",
    "l2Changer = callbacks.LambdaCallback(on_epoch_end=changeAlpha)\n",
    "\n",
    "\n",
    "base_lr = 2e-3\n",
    "decay = 0.99\n",
    "optim = keras.optimizers.Adam(lr=base_lr)\n",
    "\n",
    "model['student_reg'] = models.SoftStudentModel(input_shape, num_classes, l1=0.1, l2=l2_weight, b=1)\n",
    "model['student_reg'].compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=optim,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "47/47 [==============================] - 24s 511ms/step - loss: 1.4761 - acc: 0.9780 - val_loss: 0.3694 - val_acc: 0.9844\n",
      "Epoch 2/100\n",
      "10/47 [=====>........................] - ETA: 17s - loss: 1.5023 - acc: 0.9609"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-c45b21e478ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                                                            \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                                                            \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                                                            callbacks=[checkpointer, ls, l2Changer])\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'student_reg'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'student_reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'student_reg'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/acar/.virtualenvs/mask_rcnn/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def schedule(epoch):\n",
    "    return base_lr * decay**(epoch)\n",
    "\n",
    "ls = callbacks.LearningRateScheduler(schedule)\n",
    "#model['student_reg'].load_weights('saved_models/weights.best.student_reg.hdf5')\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.student_reg.hdf5', \n",
    "                               verbose=0, save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "# hist['student_reg'] = model['student_reg'].fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=100,\n",
    "#           verbose=1,\n",
    "#           validation_data=(x_test, y_test),\n",
    "#           callbacks=[ls,checkpointer, l2Changer],\n",
    "#             )\n",
    "\n",
    "hist['student_reg'] = model['student_reg'].fit_generator(train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                                                           steps_per_epoch=len(x_train) // batch_size + 1, \n",
    "                                                           epochs=100, verbose=1, \n",
    "                                                           validation_data=test_datagen.flow(x_test, y_test), \n",
    "                                                           validation_steps=len(x_test) // batch_size,\n",
    "                                                           callbacks=[checkpointer, ls, l2Changer])\n",
    "score['student_reg'] = model['student_reg'].evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score['student_reg'][0])\n",
    "print('Test accuracy:', score['student_reg'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8960"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.3785821808552168\n",
      "Test accuracy: 0.9912019880815264\n",
      "Test errors: 87\n"
     ]
    }
   ],
   "source": [
    "model['student_reg'].load_weights('saved_models/weights.best.student_reg.hdf5')\n",
    "score['student_reg'] = model['student_reg'].evaluate_generator(test_datagen.flow(x_test, y_test),\n",
    "                                                               steps= len(x_test), verbose=0)\n",
    "n_errors = np.int((1-score['student_reg'][-1])*len(y_test))\n",
    "print('Test loss:', score['student_reg'][0])\n",
    "print('Test accuracy:', score['student_reg'][-1])\n",
    "print('Test errors:', n_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 49s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model['student_reg'].predict_generator(test_datagen.flow(x_test, y_test), steps=len(x_test) / 1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = np.argmax(preds, axis=-1)\n",
    "np.mean(np.argmax(y_test, axis=-1) == p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 3s 58us/step\n",
      "60000/60000 [==============================] - 6s 96us/step\n",
      "60000/60000 [==============================] - 11s 182us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3622794, 0.53431916)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#T = 20\n",
    "preds['teacher_no_T'] = model['teacher'].predict(x_train, verbose=1, batch_size=batch_size)\n",
    "preds['teacher'] = model['teacher'].T_model(T).predict(x_train, verbose=1, batch_size=batch_size)\n",
    "preds['soft_teacher'] = model['soft_teacher'].predict(x_train, verbose=1, batch_size=batch_size)\n",
    "\n",
    "import numpy as np\n",
    "np.linalg.norm(preds['teacher'], axis=-1).mean(), np.linalg.norm(preds['soft_teacher'], axis=-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot constrained softmax probabilities generated by the model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "ind = np.random.choice(len(preds['teacher_no_T']), 50)\n",
    "plt.plot(np.sort(preds['teacher_no_T'])[ind].T)\n",
    "plt.show()\n",
    "\n",
    "ind = np.random.choice(len(preds['teacher']), 50)\n",
    "plt.plot(np.sort(preds['teacher'])[ind].T)\n",
    "plt.show()\n",
    "\n",
    "ind = np.random.choice(len(preds['soft_teacher']), 500)\n",
    "plt.plot(np.sort(preds['soft_teacher'])[ind].T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((1, 8), 6651),\n",
       " ((7, 9), 6180),\n",
       " ((3, 5), 6073),\n",
       " ((0, 8), 5912),\n",
       " ((6, 8), 5889),\n",
       " ((2, 8), 5884),\n",
       " ((9, 8), 5848),\n",
       " ((4, 9), 5843),\n",
       " ((8, 5), 5713),\n",
       " ((5, 8), 5393),\n",
       " ((8, 9), 99),\n",
       " ((7, 2), 60),\n",
       " ((1, 7), 53),\n",
       " ((9, 4), 47),\n",
       " ((9, 7), 44),\n",
       " ((7, 1), 24),\n",
       " ((2, 7), 24),\n",
       " ((1, 4), 23),\n",
       " ((5, 3), 23),\n",
       " ((3, 2), 23)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "pairs = [(x[-1], x[-2]) for x in np.argsort(preds['soft_teacher'])]\n",
    "counts = Counter(pairs)\n",
    "counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x180 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.random.randint(len(x_train))\n",
    "#i = 54270\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10,2.5), gridspec_kw={'width_ratios': [1.6, 2, 2], 'wspace': 0.3})\n",
    "# plt.tight_layout()\n",
    "plt.gcf().subplots_adjust(bottom=0.2)\n",
    "ax[0].imshow(x_train[i][:,:,0], cmap='gray', vmin=0, vmax=1)\n",
    "ax[0].axis('off')\n",
    "ax[0].set_title('Input')\n",
    "ax[1].bar(np.linspace(0,9,10), preds['soft_teacher'][i])\n",
    "ax[1].set_xticks(np.arange(0, 10, step=1))\n",
    "ax[1].set_ylim(top=0.7)\n",
    "ax[1].spines['top'].set_visible(False)\n",
    "ax[1].spines['right'].set_visible(False)\n",
    "ax[1].set_xlabel('Classes')\n",
    "ax[1].set_ylabel('Probabilities')\n",
    "ax[1].set_title('Regularized Network')\n",
    "ax[2].bar(np.linspace(0,9,10), preds['teacher'][i])\n",
    "ax[2].set_xticks(np.arange(0, 10, step=1))\n",
    "ax[2].set_ylim(top=0.7)\n",
    "ax[2].spines['top'].set_visible(False)\n",
    "ax[2].spines['right'].set_visible(False)\n",
    "ax[2].set_xlabel('Classes')\n",
    "ax[2].set_ylabel('Probabilities')\n",
    "ax[2].set_title('Regular Network (T=20)')\n",
    "plt.savefig('figures/mnsit_{}.pdf'.format(i))\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('foo.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54270"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "pairs = [(x[0], x[1]) for x in np.argsort(preds_st)]\n",
    "counts = Counter(pairs)\n",
    "counts.most_common(len(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   3,   7,   9,  10,  66],\n",
       "       [  0,   2,   3,   4,   6, 100]], dtype=int32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "a = [[1, 10, 7, 9, 3, 66], [6, 4, 3, 2, 100, 0]]\n",
    "b = tf.sort(a,axis=-1,direction='ASCENDING',name=None)\n",
    "c = tf.keras.backend.eval(b)\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mask_rcnn",
   "language": "python",
   "name": "mask_rcnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
